<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · Photon</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../"><img class="logo" src="../assets/logo.png" alt="Photon logo"/></a><h1>Photon</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li class="current"><a class="toctext" href>API</a><ul class="internal"></ul></li><li><a class="toctext" href="../community/">Community</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>API</a></li></ul><a class="edit-page" href="https://github.com/neurallayer/Photon.jl/blob/master/docs/src/api.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>API</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="API-1" href="#API-1">API</a></h1><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.GRU" href="#Photon.GRU"><code>Photon.GRU</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Create a GRU layer</p><p><strong>Examples:</strong></p><pre><code class="language-none">layer = GRU(50)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/recurrent.jl#L110-L118">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.KorA-Tuple{Array}" href="#Photon.KorA-Tuple{Array}"><code>Photon.KorA</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>KorA makes it easy to move an array to the GPU or the other way around</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/core.jl#L93-L95">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.LSTM" href="#Photon.LSTM"><code>Photon.LSTM</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Create a LSTM layer.</p><p><strong>Examples:</strong></p><pre><code class="language-none">layer = LSTM(50)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/recurrent.jl#L86-L94">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.RNN" href="#Photon.RNN"><code>Photon.RNN</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>A simple RNN layer.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/recurrent.jl#L67-L69">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.fit!" href="#Photon.fit!"><code>Photon.fit!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Train the model based on a supervised dataset and for a number of epochs. fit! can be called multiple times and will continue to train where is left of last time.</p><p>By default the fit! function will try to ensure the data is of the right type (e.g. Float32) and on the right device (e.g. GPU) before feeding it to the model.</p><p><strong>Usage</strong></p><pre><code class="language-julia">fit!(workout, traindata)
fit!(workout, traindata, testdata, epochs=50)</code></pre><p>If you don&#39;t want any data conversion, just pass the identity funciton as the convertor:</p><pre><code class="language-julia">fit!(workout, traindata, convertor=identity)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L260-L282">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.freeze!-Tuple{AutoGrad.Param}" href="#Photon.freeze!-Tuple{AutoGrad.Param}"><code>Photon.freeze!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Freeze a parameter so it no longer will be updated during training.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L178-L180">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.hasmetric-Tuple{Workout,Symbol}" href="#Photon.hasmetric-Tuple{Workout,Symbol}"><code>Photon.hasmetric</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Does the workout have any recorded values for a certain metric</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L98-L100">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.loadWorkout-Tuple{Any}" href="#Photon.loadWorkout-Tuple{Any}"><code>Photon.loadWorkout</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Load a workout from file and return it.</p><p><strong>Usage</strong></p><pre><code class="language-julia">workout = loadWorkout(&quot;workout_1000.dat&quot;)
fit!(workout, mydata)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L73-L82">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.output_size-Tuple{Photon.Conv,Any}" href="#Photon.output_size-Tuple{Photon.Conv,Any}"><code>Photon.output_size</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Utility function to determine the output size of a convolutional layer given a certain input size and configuration of a convolutional layer. This function works even if the weights of the layer are not initialized.</p><p>For example: 	c = Conv2D(16, (3,3), strides=3, padding=1) 	output_size(c, (224,224)) # output is (75, 75)</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/conv.jl#L78-L87">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.plotmetrics" href="#Photon.plotmetrics"><code>Photon.plotmetrics</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Plot the metrics after some training. This function will plot all the metrics in a single graph.</p><p>In order to avoid Photon being dependend on Plots, the calling code will have to provide that module as the first parameter.</p><p><strong>Usage</strong></p><pre><code class="language-julia">fit!(workout, mydata, epochs=10)

import Plots
plotmetrics(Plots, workout)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/utils.jl#L5-L20">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.predict-Tuple{Any,Any}" href="#Photon.predict-Tuple{Any,Any}"><code>Photon.predict</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Predict a sample, either a single value or a batch. Compared to invoking the model directory with model(x), predit takes care of:</p><ul><li>Moving the data to the GPU if required.</li><li>Making the data into a batch (controlled by makebatch parameter)</li></ul><p><strong>Usage</strong></p><pre><code class="language-julia">x = randn(Float32, 224, 224, 3)
predict(model, x)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L228-L241">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.saveWorkout" href="#Photon.saveWorkout"><code>Photon.saveWorkout</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Save a workout to a file. This will save all the state that is captured in the workout and enables to continue at a later stage.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L63-L66">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.unfreeze!-Tuple{AutoGrad.Param}" href="#Photon.unfreeze!-Tuple{AutoGrad.Param}"><code>Photon.unfreeze!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Unfreeze a parameter so it will be updated again during training.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L185-L187">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.AdaptiveAvgPool" href="#Photon.AdaptiveAvgPool"><code>Photon.AdaptiveAvgPool</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adaptive Average Pool has a fixed size output and enables creating a convolutional network that can be used for multiple image formats.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/conv.jl#L214-L217">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.AdaptiveMaxPool" href="#Photon.AdaptiveMaxPool"><code>Photon.AdaptiveMaxPool</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adaptive MaxPool has a fixed size output and enables creating a convolutional network that can be used for multiple image formats.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/conv.jl#L260-L263">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.BCELoss" href="#Photon.BCELoss"><code>Photon.BCELoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Binary CrossEntropy</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/losses.jl#L61-L63">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.BatchNorm" href="#Photon.BatchNorm"><code>Photon.BatchNorm</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>BatchNorm layer with support for an optional activation function</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/core.jl#L149-L151">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Concurrent" href="#Photon.Concurrent"><code>Photon.Concurrent</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Concurrrent layer allows for stacking a number of other layers in parallel and combining their results before returning it.</p><p>This layer will stack on the second last dimension. So with 2D and 3D convolution this will be the channel layer (WxHxCxN). As a result other dimensions have to the same.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/container.jl#L40-L47">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.ContextSwitch" href="#Photon.ContextSwitch"><code>Photon.ContextSwitch</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Beginning of allowing for a single model instance to run on multiple devices (expiremental)</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/core.jl#L166-L169">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.CrossEntropyLoss" href="#Photon.CrossEntropyLoss"><code>Photon.CrossEntropyLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>CrossEntropy loss function with support for an optional weight parameter. The weight parameter can be static (for example to handle class inbalances) or dynamic (so passed every time when the lost function is invoked)</p><p><strong>Usage</strong></p><pre><code class="language-julia">workout = Workout(model, CE(), SGD())</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/losses.jl#L77-L88">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Dense" href="#Photon.Dense"><code>Photon.Dense</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Fully connected layer with an optional bias weight.</p><p><strong>Usage</strong></p><pre><code class="language-julia">layer = Dense(10, relu)
layer = Dense(100, use_bias=false)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/core.jl#L52-L62">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Dropout" href="#Photon.Dropout"><code>Photon.Dropout</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Dropout layer with optional the rate (between 0 and 1) of dropout. If no rate is specified, 0.5 (so 50%) will be used.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/core.jl#L131-L134">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Flatten" href="#Photon.Flatten"><code>Photon.Flatten</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Flattening Layer. Photon by default already has flattening funcitonality build into the Dense layer, so you won&#39;t need to include a separate Flatten layer before a Dense layer.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/core.jl#L106-L110">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.HingeLoss" href="#Photon.HingeLoss"><code>Photon.HingeLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Hinge Loss implementation</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/losses.jl#L119-L121">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.MAELoss" href="#Photon.MAELoss"><code>Photon.MAELoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Mean Absolute Error implementation, also referred to as the L1 Loss.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/losses.jl#L45-L48">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.MSELoss" href="#Photon.MSELoss"><code>Photon.MSELoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Mean Square Error implementation, also referred to as the L2 Loss.</p><p><strong>Usage</strong></p><pre><code class="language-julia">workout = Workout(model, MSELoss(), SGD())</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/losses.jl#L22-L31">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.PseudoHuberLoss" href="#Photon.PseudoHuberLoss"><code>Photon.PseudoHuberLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Pseudo Huber Loss implementation, somewhere between a L1 and L2 loss.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/losses.jl#L103-L105">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Residual" href="#Photon.Residual"><code>Photon.Residual</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Residual Layer works like a Sequential layer, however before returning the result it will be combined with the orginal input (residual). This is a popular techique in modern neural networds since it allows for better backpropagation.</p><p>This will stack on the second last dimension. So with 2D and 3D convolution this will be the channel layer (WxHxCxN)</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/container.jl#L63-L70">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Sequential" href="#Photon.Sequential"><code>Photon.Sequential</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Sequential layer allows to chain together a number of other layers.</p><p><strong>Usage</strong></p><pre><code class="language-julia">model = Sequential(Conv2D(100),MaxPool(),Dense(10))</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/container.jl#L16-L25">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Workout" href="#Photon.Workout"><code>Photon.Workout</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>The Workout keeps track of the progress of the training session. At least a model and a loss function needs to be provided. Optional an optimizer and one or more metrics can be specified.</p><p>If no optimizer is provided, SGD will be used. If no metrics are provided, only the loss during training and validation will be registered (:loss and :val_loss).</p><p><strong>Usage</strong></p><pre><code class="language-julia">workout = Workout(model, mse)

workout = Workout(model, nll, SGD())

workout = Workout(model, nll, SGD(); acc=BinaryAccuracy())</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L14-L31">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.autoConvertor-Tuple{Array}" href="#Photon.autoConvertor-Tuple{Array}"><code>Photon.autoConvertor</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>autoConvertor converts data to the right format for a model. It uses the context to determine the device (cpu or gpu) and datatype that the data needs to be.</p><p>It supports Tuples, Arrays and KnetArrays and a combination of those.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/core.jl#L111-L117">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.back!-Tuple{AutoGrad.Tape,Any}" href="#Photon.back!-Tuple{AutoGrad.Tape,Any}"><code>Photon.back!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Perform the back propagation and update of weights in one go.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L193-L195">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.getmetricname" href="#Photon.getmetricname"><code>Photon.getmetricname</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Function to generate the fully qualified metric name. It uses the metric name and phase (train or valid) to come up with a unique name.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L104-L107">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.getmetricvalue" href="#Photon.getmetricvalue"><code>Photon.getmetricvalue</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Get the metric value for a fully qualified metric name and a certain step. If step is not provided the last step will be used. If no value is found the passed function will not be invoked.</p><p><strong>Usage</strong></p><pre><code class="language-julia">getmetricvalue(workout, :val_loss) do value
    println(&quot;validation loss&quot;, value)
end</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L138-L150">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.gradients" href="#Photon.gradients"><code>Photon.gradients</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Utility function to calculate the gradients. Useful when checking for vanishing or exploding gradients. The returned value is a Vector of (Param, Gradient).</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L160-L163">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.step!-Tuple{Workout,Any,Any}" href="#Photon.step!-Tuple{Workout,Any,Any}"><code>Photon.step!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Take a single step in updating the weights of a model. This function will be invoked from fit! to do the actual learning.</p><p>For a minibatch (x,y) of data, the folowing sequence will be executed:</p><ol><li>perform the forward pass</li><li>calculate the loss</li><li>update and remember the metrics, if any</li><li>do the backpropagation and update the weights</li></ol></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L205-L215">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.stop-Tuple{Workout,String}" href="#Photon.stop-Tuple{Workout,String}"><code>Photon.stop</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Stop a training session. If this is called outside the scope of a trianing session, just an error is thrown.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L89-L92">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.updatemetrics!" href="#Photon.updatemetrics!"><code>Photon.updatemetrics!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Invoke the configured metrics. The loss metric will always be logged and available. Metrics are stored in the history attribute of the workout.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L113-L116">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.validate-Tuple{Workout,Any,Any}" href="#Photon.validate-Tuple{Workout,Any,Any}"><code>Photon.validate</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Validate a minibatch and calculate the loss and metrics. Typically this function is called from the fit! method.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L249-L252">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Serialization.serialize-Tuple{Serialization.AbstractSerializer,Knet.KnetArray}" href="#Serialization.serialize-Tuple{Serialization.AbstractSerializer,Knet.KnetArray}"><code>Serialization.serialize</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Enable saving and loading of models by specialized KnetArray methods for Julia serialization This will effectively move a GPU weight to the CPU before serialing it and move it back to the GPU when deserializing.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/train.jl#L47-L51">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Context" href="#Photon.Context"><code>Photon.Context</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Context is used by various parts of Photon to determine what the device and datatype should be for Arrays. It also allows to quickly switch between GPU and CPU based models.</p><p><strong>Attributes</strong></p><ul><li>device::Symbol the type of device. For now supported :cpu and :gpu</li><li>deviceId::Int the id of the device, useful for example if you multiple GPU&#39;s</li><li>dtype::Type the type of data you want to use. Most common are Float32, Float16 or Float64.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/core.jl#L46-L55">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Conv" href="#Photon.Conv"><code>Photon.Conv</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Convolutional layer that serves as the base for Conv2D and Conv3D</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/conv.jl#L6-L8">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.ConvTranspose" href="#Photon.ConvTranspose"><code>Photon.ConvTranspose</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>ConvTranspose layer</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/conv.jl#L110-L112">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Loss" href="#Photon.Loss"><code>Photon.Loss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Base type for the loss functions. However Photon accepts any functoon as a loss function as long as it is callable and returns the loss as a scalar value.</p><pre><code class="language-julia"> fn(y_pred, y_true) :: Number</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/core.jl#L24-L32">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Meter" href="#Photon.Meter"><code>Photon.Meter</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>A meter is reponsible for presenting metric values. This can be printing it to the console output, showing it on TensorBoard of storing it in a database.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/core.jl#L8-L12">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.PoolingLayer" href="#Photon.PoolingLayer"><code>Photon.PoolingLayer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Pooling layers</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/conv.jl#L185-L187">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.StackedLayer" href="#Photon.StackedLayer"><code>Photon.StackedLayer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Common behavior for stacked layers that enables to access them as arrays</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/f629693f22b52bcd8170bb81087d08ab877d5851/src/layers/container.jl#L4-L6">source</a></section><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Home</span></a><a class="next" href="../community/"><span class="direction">Next</span><span class="title">Community</span></a></footer></article></body></html>
