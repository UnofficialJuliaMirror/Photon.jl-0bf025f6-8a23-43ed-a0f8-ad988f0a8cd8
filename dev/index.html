<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · Photon</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href><img class="logo" src="assets/logo.png" alt="Photon logo"/></a><h1>Photon</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Home</a><ul class="internal"><li><a class="toctext" href="#Steps-1">Steps</a></li></ul></li><li><a class="toctext" href="api/">API</a></li><li><a class="toctext" href="community/">Community</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Home</a></li></ul><a class="edit-page" href="https://github.com/neurallayer/Photon.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Introduction-1" href="#Introduction-1">Introduction</a></h1><p>Photon is a developer friendly framework for Deep Learning in Julia. Under the hood it leverages <strong>Knet</strong> and it provides a Keras like API on top of that.</p><h2><a class="nav-anchor" id="Steps-1" href="#Steps-1">Steps</a></h2><p>To train your own model, there are four steps to follow:</p><ol><li><p>Create your <strong>model</strong> using the layers that come out of the box with Photon or using your own custom layers.</p></li><li><p>Create a <strong>workout</strong> that combines the model, a loss function and an optimiser. Optionally you can also add some metrics that you want to monitor.</p></li><li><p>Prepare your <strong>data</strong> with a Data pipeline</p></li><li><p><strong>Train</strong> the model by calling fit! on the workout and the training data.</p></li></ol><h3><a class="nav-anchor" id="Step-1:-Model-1" href="#Step-1:-Model-1">Step 1: Model</a></h3><p>A model can use out of the box layers or your own layers. Photon support most common type of layer:</p><ol><li>Dense or fully connected layers</li><li>2D ad 3D convolutional layers</li><li>Different type of Pooling layers</li><li>Recurrent layers (RNN, LSTM, GRU)</li><li>Dropout layers</li><li>Several types of container layers like Sequential and Residual</li></ol><p>Some examples how to create the different type of models:</p><pre><code class="language-julia">mymodel = Sequential(
            Dense(64, relu),
            Dense(10)
)</code></pre><pre><code class="language-julia">mymodel = Sequential(
            Conv2D(64, 3, relu),
            Conv2D(64, 3, relu),
            MaxPool(),
            Dense(10)
)</code></pre><pre><code class="language-julia">mymodel = Sequential(
            LSTM(64),
            Dense(64),
            Dense(10)
)</code></pre><p>So normally you won&#39;t need to create your own layers. But if you have to, a layer is nothing more than function. So the following could be a layer ;)</p><pre><code class="language-julia">myLayer(X) = moon == :full ? X .- 1 : X</code></pre><h3><a class="nav-anchor" id="Step-2:-Workout-1" href="#Step-2:-Workout-1">Step 2: Workout</a></h3><p>A workout combines a model + loss + optimiser and keeps track of the progress during the actual training. The workout is stateful in the sense that you can run multiple training sessions and the progress will be recorded appropriately.   </p><p>The minimum required to create a workout is:</p><pre><code class="language-julia">workout = Workout(mymodel, MSE())</code></pre><p>Besides this, you can pass an optimizer and define the metrics that you want to get tracked during the training sessions. Photon tracks :loss and :val_loss (for the validation phase) by default, but you define additional ones.</p><pre><code class="language-julia">workout = Workout(mymodel, MSE(), SGD(), acc=accuracy())</code></pre><h3><a class="nav-anchor" id="Step-3:-Data-1" href="#Step-3:-Data-1">Step 3: Data</a></h3><p>Although Photon is perfectly happy to work on plain Vectors of data, this often won&#39;t be feasible due to the data not fitting in memory. In those cases you can use the data pipeline feature of Photon.</p><p>A typical pipeline would look something like this:</p><pre><code class="language-julia">  data = SomeDataset(source) |&gt; SomeTransformers() |&gt; MiniBatch()</code></pre><p>Add then the pipeline can be used directly in the training cycle:</p><pre><code class="language-julia">  fit!(workout, data)</code></pre><p>Photon comes out the box with several reusable components for creating these pipelines. They can be divided into two types; <em>Datasets</em> that are the start of a pipeline and retrieve the data from some source and <em>Transformers</em> that transform the output of a previous step.</p><p><strong>Source datasets</strong></p><ul><li>ImageDataset</li><li>TestDataset</li><li>ArrayDataset</li><li>JLDDataset</li></ul><p><strong>Transformers</strong></p><ul><li>Normalizer</li><li>Cropper</li><li>MiniBatch</li><li>Noiser</li></ul><p>A complete pipeline for image data could look something like this:</p><pre><code class="language-julia">data = ImageDataset(files, labels, resize=(250,250))
data = data |&gt; Crop(200,200) |&gt; Normalize() |&gt; MiniBatch(8)</code></pre><h3><a class="nav-anchor" id="Step-4:-Train-1" href="#Step-4:-Train-1">Step 4: Train</a></h3><p>The actual training in Photon is done invoking the fit! function.</p><pre><code class="language-julia">fit!(workout, data, epochs=5)</code></pre><p>The validation phase is optional. But if you provide data for the validation phase, Photon will automatically run a validation after each training epoch.</p><pre><code class="language-julia">fit!(workout, data, training_data, epochs=10)</code></pre><p>Defined metrics and loss will then be available both for training and validation.</p><p>The data is expected to be a tuple of (X, Y) where X and Y can be tuples again in case your model expects multiple inputs or outputs. So some examples of valid formats</p><pre><code class="language-julia">(X,Y)
((X1,X2), Y)
(X, (Y1, Y2, Y3))
((X1, X2), (Y1, Y2))</code></pre><p>By default fit! will convert each batch to the right data type and device. This is controlled by the optional parameter <em>convertor</em>. If you don&#39;t want a conversion to take place and ensured the provided data is already in the right format, you can pass the identity function:</p><pre><code class="language-julia">fit!(workout, data; convertor=identity)</code></pre><footer><hr/><a class="next" href="api/"><span class="direction">Next</span><span class="title">API</span></a></footer></article></body></html>
