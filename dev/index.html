<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · Photon</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href><img class="logo" src="assets/logo.png" alt="Photon logo"/></a><h1>Photon</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Home</a><ul class="internal"><li><a class="toctext" href="#Steps-1">Steps</a></li><li><a class="toctext" href="#API-1">API</a></li></ul></li><li><a class="toctext" href="community/">Community</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Home</a></li></ul><a class="edit-page" href="https://github.com/neurallayer/Photon.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Photon-1" href="#Photon-1">Photon</a></h1><p><strong>Photon</strong> is a developer friendly framework for Deep Learning in Julia. Under the hood it leverages <strong>Knet</strong> and it provides a Keras like API on top of that.</p><h2><a class="nav-anchor" id="Steps-1" href="#Steps-1">Steps</a></h2><p>To train your own model, there are three steps to follow:</p><ol><li><p>Create your model using the layers that come out of the box with Photon or using your own custom layers.</p></li><li><p>Create a <em>Workout</em> that combines the model, a loss function and an optimiser. Optionally you can also add some metrics that you want to monitor.</p></li><li><p>Train the model by calling fit! on the workout and the training data.</p></li></ol><h3><a class="nav-anchor" id="Step-1:-Model-1" href="#Step-1:-Model-1">Step 1: Model</a></h3><p>A model can use out of the box layers or your own layers. Photon support most common type of layer:</p><ol><li>Dense or fully connected layers.</li><li>2D ad 3D convolutional layers</li><li>Different type of Pooling layers</li><li>Recurrent layers (RNN, LSTM, GRU)</li><li>Dropout layers.</li><li>Several container type layers like Sequential and Residual</li></ol><p>Some examples how to create the different type of models:</p><pre><code class="language-julia">mymodel = Sequential(
            Dense(64, relu),
            Dense(10)
)</code></pre><pre><code class="language-julia">mymodel = Sequential(
            Conv2D(64, 3, relu),
            Conv2D(64, 3, relu),
            MaxPool(),
            Dense(10)
)</code></pre><pre><code class="language-julia">mymodel = Sequential(
            LSTM(64),
            Dense(64),
            Dense(10)
)</code></pre><p>So normally you won&#39;t need to create your own layers. But if you have to, a layer is nothing more than function. So the following could be a layer ;)</p><pre><code class="language-julia">myLayer(X) = moon == :full ? X .- 1 : X</code></pre><h3><a class="nav-anchor" id="Step-2:-Workout-1" href="#Step-2:-Workout-1">Step 2: Workout</a></h3><p>A workout combines a model + loss + optimiser and keeps track of the progress during the actual training. The workout is stateful in the sense that you can run multiple training sessions and the progress will be recorded appropriately.   </p><p>The minimum required to create a workout is:</p><pre><code class="language-julia">workout = Workout(mymodel, MSE())</code></pre><p>Besides this, you can pass an optimzer and define the metrics that you want to get tracked during the training sessions. Photon tracks :loss and :val_loss (for the validation phase) by default, but you define additional ones.</p><pre><code class="language-julia">workout = Workout(mymodel, MSE(), SGD(), acc=accuracy())</code></pre><h3><a class="nav-anchor" id="Step-3:-fit!-1" href="#Step-3:-fit!-1">Step 3: fit!</a></h3><p>The actual training is done using the fit! function.</p><pre><code class="language-julia">fit!(workout, data, epochs=5)</code></pre><p>If you provide also data for the validation phase, Photon will automatically run a validation after a training epoch has finished.</p><pre><code class="language-julia">fit!(workout, data, training_data, epochs=10)</code></pre><p>The data is expected to be a tuple of (X, Y) where X and Y can be tuples again in case your model expects multiple inputs or outputs. So some examples of valid formats</p><pre><code class="language-julia">(X,Y)
((X2,X2), Y)
(X, (Y1, Y2, Y3))
((X1, X2), (Y1, Y2))</code></pre><p>By default fit! will convert each batch to the right data type and device. This is controlled by the optional parameter <em>convertor</em>. If you don&#39;t want a convertor and ensure the provided data is already in the right format, you can pass the identity function:</p><pre><code class="language-julia">fit!(workout, data; convertor=identity)</code></pre><h2><a class="nav-anchor" id="API-1" href="#API-1">API</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.GRU" href="#Photon.GRU"><code>Photon.GRU</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Create a GRU layer</p><p><strong>Examples:</strong></p><pre><code class="language-none">layer = GRU(50)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/recurrent.jl#L110-L118">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.KorA-Tuple{Array}" href="#Photon.KorA-Tuple{Array}"><code>Photon.KorA</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>KorA makes it easy to move an array to the GPU or the other way around</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/core.jl#L93-L95">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.LSTM" href="#Photon.LSTM"><code>Photon.LSTM</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Create a LSTM layer.</p><p><strong>Examples:</strong></p><pre><code class="language-none">layer = LSTM(50)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/recurrent.jl#L86-L94">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.RNN" href="#Photon.RNN"><code>Photon.RNN</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>A simple RNN layer.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/recurrent.jl#L67-L69">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.fit!" href="#Photon.fit!"><code>Photon.fit!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Train the model based on a supervised dataset and for a number of epochs. fit! can be called multiple times and will continue to train where is left of last time.</p><p>By default the fit! function will try to ensure the data is of the right type (e.g. Float32) and on the right device (e.g. GPU) before feeding it to the model.</p><p><strong>Usage</strong></p><pre><code class="language-julia">fit!(workout, traindata)
fit!(workout, traindata, testdata, epochs=50)</code></pre><p>If you don&#39;t want any data conversion, just pass the identity funciton as the convertor:</p><pre><code class="language-julia">fit!(workout, traindata, convertor=identity)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L236-L258">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.hasmetric-Tuple{Workout,Symbol}" href="#Photon.hasmetric-Tuple{Workout,Symbol}"><code>Photon.hasmetric</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Does the workout have any recorded values for a certain metric</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L89-L91">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.loadWorkout-Tuple{Any}" href="#Photon.loadWorkout-Tuple{Any}"><code>Photon.loadWorkout</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Load a workout from file and return it.</p><p><strong>Usage</strong></p><pre><code class="language-julia">workout = loadWorkout(&quot;workout_1000.dat&quot;)
fit!(workout, mydata)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L72-L81">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.output_size-Tuple{Photon.Conv,Any}" href="#Photon.output_size-Tuple{Photon.Conv,Any}"><code>Photon.output_size</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Utility function to determine the output size of a convolutional layer given a certain input size and configuration of a convolutional layer. This function works even if the weights of the layer are not initialized.</p><p>For example: 	c = Conv2D(16, (3,3), strides=3, padding=1) 	output_size(c, (224,224)) # output is (75, 75)</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/conv.jl#L78-L87">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.plotmetrics" href="#Photon.plotmetrics"><code>Photon.plotmetrics</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Plot the metrics after some training. This function will plot all the metrics in a single graph.</p><p>In order to avoid Photon being dependend on Plots, the calling code will have to provide that module as the first parameter.</p><p><strong>Usage</strong></p><pre><code class="language-julia">fit!(workout, mydata, epochs=10)

import Plots
plotmetrics(Plots, workout)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/utils.jl#L5-L20">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.predict-Tuple{Any,Any}" href="#Photon.predict-Tuple{Any,Any}"><code>Photon.predict</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Predict a sample, either a single value or a batch. Compared to invoking the model directory with model(x), predit takes care of:</p><ul><li>Moving the data to the GPU if required.</li><li>Making the data into a batch (controlled by makebatch parameter)</li></ul><p><strong>Usage</strong></p><pre><code class="language-julia">x = randn(Float32, 224, 224, 3)
predict(model, x)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L204-L217">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.saveWorkout" href="#Photon.saveWorkout"><code>Photon.saveWorkout</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Save a workout to a file. This will save all the state that is captured in the workout and enables to continue at a later stage.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L62-L65">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.AdaptiveAvgPool" href="#Photon.AdaptiveAvgPool"><code>Photon.AdaptiveAvgPool</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adaptive Average Pool has a fixed size output and enables creating a convolutional network that can be used for multiple image formats.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/conv.jl#L214-L217">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.AdaptiveMaxPool" href="#Photon.AdaptiveMaxPool"><code>Photon.AdaptiveMaxPool</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adaptive MaxPool has a fixed size output and enables creating a convolutional network that can be used for multiple image formats.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/conv.jl#L260-L263">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.BCELoss" href="#Photon.BCELoss"><code>Photon.BCELoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Binary CrossEntropy</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/losses.jl#L61-L63">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.BatchNorm" href="#Photon.BatchNorm"><code>Photon.BatchNorm</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>BatchNorm layer with support for an optional activation function</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/core.jl#L149-L151">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Concurrent" href="#Photon.Concurrent"><code>Photon.Concurrent</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Concurrrent</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/container.jl#L33-L35">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.ContextSwitch" href="#Photon.ContextSwitch"><code>Photon.ContextSwitch</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Beginning of allowing for a single model instance to run on multiple devices (expiremental)</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/core.jl#L166-L169">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.CrossEntropyLoss" href="#Photon.CrossEntropyLoss"><code>Photon.CrossEntropyLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>CrossEntropy loss function with support for an optional weight parameter. The weight parameter can be static (for example to handle class inbalances) or dynamic (so passed every time when the lost function is invoked)</p><p><strong>Usage</strong></p><pre><code class="language-julia">workout = Workout(model, CE(), SGD())</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/losses.jl#L77-L88">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Dense" href="#Photon.Dense"><code>Photon.Dense</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Fully connected layer with an optional bias weight.</p><p><strong>Usage</strong></p><pre><code class="language-julia">layer = Dense(10, relu)
layer = Dense(100, use_bias=false)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/core.jl#L52-L62">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Dropout" href="#Photon.Dropout"><code>Photon.Dropout</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Dropout layer with optional the rate (between 0 and 1) of dropout. If no rate is specified, 0.5 (so 50%) will be used.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/core.jl#L131-L134">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Flatten" href="#Photon.Flatten"><code>Photon.Flatten</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Flattening Layer. Photon by default already has flattening funcitonality build into the Dense layer, so you won&#39;t need to include a separate Flatten layer before a Dense layer.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/core.jl#L106-L110">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.HingeLoss" href="#Photon.HingeLoss"><code>Photon.HingeLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Hinge Loss implementation</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/losses.jl#L119-L121">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.MAELoss" href="#Photon.MAELoss"><code>Photon.MAELoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Mean Absolute Error implementation, also referred to as the L1 Loss.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/losses.jl#L45-L48">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.MSELoss" href="#Photon.MSELoss"><code>Photon.MSELoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Mean Square Error implementation, also referred to as the L2 Loss.</p><p><strong>Usage</strong></p><pre><code class="language-julia">workout = Workout(model, MSELoss(), SGD())</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/losses.jl#L22-L31">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.PseudoHuberLoss" href="#Photon.PseudoHuberLoss"><code>Photon.PseudoHuberLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Pseudo Huber Loss implementation, somewhere between a L1 and L2 loss.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/losses.jl#L103-L105">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Residual" href="#Photon.Residual"><code>Photon.Residual</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Residual Layer. This will stack on the second last dimension. So with and 2D convolution this will be the channel layer (WxHxCxN)</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/container.jl#L51-L54">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Sequential" href="#Photon.Sequential"><code>Photon.Sequential</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Sequential</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/container.jl#L16-L18">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Workout" href="#Photon.Workout"><code>Photon.Workout</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>The Workout keeps track of the progress of the training session. At least a model and a loss function needs to be provided. Optional an optimizer and one or more metrics can be specified.</p><p>If no optimizer is provided, SGD will be used. If no metrics are provided, only the loss during training and validation will be registered (:loss and :val_loss).</p><p><strong>Usage</strong></p><pre><code class="language-julia">workout = Workout(model, mse)

workout = Workout(model, nll, SGD())

workout = Workout(model, nll, SGD(); acc=BinaryAccuracy())</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L13-L30">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.autoConvertor-Tuple{Array}" href="#Photon.autoConvertor-Tuple{Array}"><code>Photon.autoConvertor</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>autoConvertor converts data to the right format for a model. It uses the context to determine the device (cpu or gpu) and datatype that the data needs to be.</p><p>It supports Tuples, Arrays and KnetArrays and a combination of those.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/core.jl#L111-L117">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.back!-Tuple{AutoGrad.Tape,Any}" href="#Photon.back!-Tuple{AutoGrad.Tape,Any}"><code>Photon.back!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Perform the back propagation and update of weights in one go.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L170-L172">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.getmetricname" href="#Photon.getmetricname"><code>Photon.getmetricname</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Function to generate the fully qualified metric name. It uses the metric name and phase (train or valid) to come up with a unique name.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L95-L98">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.getmetricvalue" href="#Photon.getmetricvalue"><code>Photon.getmetricvalue</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Get the metric value for a fully qualified metric name and a certain step. If step is not provided the last step is used. If no value is found the passed function will not be invoked.</p><p><strong>Usage</strong></p><pre><code class="language-julia">getmetricvalue(workout, :val_loss) do value
    println(&quot;validation loss&quot;, value)
end</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L129-L141">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.gradients" href="#Photon.gradients"><code>Photon.gradients</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Utility function to calculate the gradients. Useful when checking for vanishing or exploding gradients. The returned value is a Vector of (Param, Gradient).</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L151-L154">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.step!-Tuple{Workout,Any,Any}" href="#Photon.step!-Tuple{Workout,Any,Any}"><code>Photon.step!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Take a single step in updating the weights of a model. This function will be invoked from fit! to do the actual learning.</p><p>For a minibatch (x,y) of data, the folowing sequence will be executed:</p><ol><li>perform the forward pass</li><li>calculate the loss</li><li>update and remember the metrics, if any</li><li>do the backpropagation and update the weights</li></ol></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L181-L191">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.updatemetrics!" href="#Photon.updatemetrics!"><code>Photon.updatemetrics!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Invoke the configured metrics. The loss metric will always be logged and available. Metrics are stored in the history attribute of the workout.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L104-L107">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.validate-Tuple{Workout,Any,Any}" href="#Photon.validate-Tuple{Workout,Any,Any}"><code>Photon.validate</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Validate a minibatch and calculate the loss and metrics. Typically this function is called from the fit! method.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L225-L228">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Serialization.serialize-Tuple{Serialization.AbstractSerializer,Knet.KnetArray}" href="#Serialization.serialize-Tuple{Serialization.AbstractSerializer,Knet.KnetArray}"><code>Serialization.serialize</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Enable saving and loading of models by specialized KnetArray methods for Julia serialization This will effectively move a GPU weight to the CPU before serialing it and move it back to the GPU when deserializing.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/train.jl#L46-L50">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Context" href="#Photon.Context"><code>Photon.Context</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Context is used by various parts of Photon to determine what the device and datatype should be for Arrays. It also allows to quickly switch between GPU and CPU based models.</p><p><strong>Attributes</strong></p><ul><li>device::Symbol the type of device. For now supported :cpu and :gpu</li><li>deviceId::Int the id of the device, useful for example if you multiple GPU&#39;s</li><li>dtype::Type the type of data you want to use. Most common are Float32, Float16 or Float64.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/core.jl#L46-L55">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Conv" href="#Photon.Conv"><code>Photon.Conv</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Convolutional layer that serves as the base for Conv2D and Conv3D</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/conv.jl#L6-L8">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.ConvTranspose" href="#Photon.ConvTranspose"><code>Photon.ConvTranspose</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>ConvTranspose layer</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/conv.jl#L110-L112">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Loss" href="#Photon.Loss"><code>Photon.Loss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Base type for the loss functions. However Photon accepts any functoon as a loss function as long as it is callable and returns the loss as a scalar value.</p><pre><code class="language-julia"> fn(y_pred, y_true) :: Number</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/core.jl#L24-L32">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Meter" href="#Photon.Meter"><code>Photon.Meter</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>A meter is reponsible for presenting metric values. This can be printing it to the console output, showing it on TensorBoard of storing it in a database.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/core.jl#L8-L12">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.PoolingLayer" href="#Photon.PoolingLayer"><code>Photon.PoolingLayer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Pooling layers</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/conv.jl#L185-L187">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.StackedLayer" href="#Photon.StackedLayer"><code>Photon.StackedLayer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Common behavior for stacked layers that enables to access them as arrays</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/ee91ad896dd96232929b45957d938c345c885ecf/src/layers/container.jl#L4-L6">source</a></section><footer><hr/><a class="next" href="community/"><span class="direction">Next</span><span class="title">Community</span></a></footer></article></body></html>
